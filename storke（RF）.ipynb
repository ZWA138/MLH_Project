{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id  seq_num icd_code  icd_version gender  anchor_age  \\\n",
      "0    10025463  24470193        1      431            9      M          66   \n",
      "1    10032725  20611640        2      431            9      F          38   \n",
      "2    10017492  27672872        1    43491            9      M          84   \n",
      "3    10017492  27417763        3      431            9      M          84   \n",
      "4    10004733  27411876        2    43491            9      M          51   \n",
      "\n",
      "   anchor_year anchor_year_group         dod  \n",
      "0         2136       2011 - 2013  2137-10-09  \n",
      "1         2143       2011 - 2013  2143-03-30  \n",
      "2         2114       2011 - 2013  2116-07-05  \n",
      "3         2114       2011 - 2013  2116-07-05  \n",
      "4         2174       2014 - 2016         NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 从 CSV 文件加载 ICD-9 数据\n",
    "diagnoses = pd.read_csv('hosp/diagnoses_icd.csv.gz')\n",
    "\n",
    "stroke_icd9_codes = ['43491', '431', '4359']  # 中风相关ICD-9代码\n",
    "\n",
    "# 筛选卒中患者\n",
    "stroke_data = diagnoses[diagnoses['icd_code'].astype(str).isin(stroke_icd9_codes)]\n",
    "\n",
    "# 加载生命体征或住院数据（假设存在 hospital_stay 和 blood_pressure 等列）\n",
    "patient_data = pd.read_csv('hosp/patients.csv.gz')\n",
    "\n",
    "# 将诊断数据与其他患者数据关联\n",
    "merged_data = pd.merge(stroke_data, patient_data, on='subject_id', how='inner')\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      itemid                                     label         abbreviation  \\\n",
      "96    227539           ART Blood Pressure Alarm Source  ART BP Alarm Source   \n",
      "2055  220058      Arterial Blood Pressure Alarm - High     ABP Alarm - High   \n",
      "2057  220056       Arterial Blood Pressure Alarm - Low      ABP Alarm - Low   \n",
      "2061  223752   Non-Invasive Blood Pressure Alarm - Low      NBP Alarm - Low   \n",
      "2073  227538            ART Blood Pressure Alarm - Low   ART BP Alarm - Low   \n",
      "2074  227537           ART Blood Pressure Alarm - High  ART BP Alarm - High   \n",
      "2078  223751  Non-Invasive Blood Pressure Alarm - High     NBP Alarm - High   \n",
      "2566  220052              Arterial Blood Pressure mean                 ABPm   \n",
      "2568  227242     Manual Blood Pressure Diastolic Right         Manual BPd R   \n",
      "2569  220180     Non Invasive Blood Pressure diastolic                 NBPd   \n",
      "2571  227243      Manual Blood Pressure Systolic Right         Manual BPs R   \n",
      "2572  220051         Arterial Blood Pressure diastolic                 ABPd   \n",
      "2575  220181          Non Invasive Blood Pressure mean                 NBPm   \n",
      "2583  224643      Manual Blood Pressure Diastolic Left         Manual BPd L   \n",
      "2584  220179      Non Invasive Blood Pressure systolic                 NBPs   \n",
      "2586  220050          Arterial Blood Pressure systolic                 ABPs   \n",
      "2591  224167       Manual Blood Pressure Systolic Left         Manual BPs L   \n",
      "\n",
      "          linksto             category unitname param_type  lownormalvalue  \\\n",
      "96    chartevents               Alarms      NaN       Text             NaN   \n",
      "2055  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2057  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2061  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2073  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2074  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2078  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2566  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2568  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2569  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2571  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2572  chartevents  Routine Vital Signs     mmHg    Numeric            60.0   \n",
      "2575  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2583  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2584  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2586  chartevents  Routine Vital Signs     mmHg    Numeric            90.0   \n",
      "2591  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "\n",
      "      highnormalvalue  \n",
      "96                NaN  \n",
      "2055              NaN  \n",
      "2057              NaN  \n",
      "2061              NaN  \n",
      "2073              NaN  \n",
      "2074              NaN  \n",
      "2078              NaN  \n",
      "2566              NaN  \n",
      "2568              NaN  \n",
      "2569              NaN  \n",
      "2571              NaN  \n",
      "2572             90.0  \n",
      "2575              NaN  \n",
      "2583              NaN  \n",
      "2584              NaN  \n",
      "2586            140.0  \n",
      "2591              NaN  \n"
     ]
    }
   ],
   "source": [
    "# 加载d_items表，查看所有监测数据项的item_id和描述\n",
    "d_items = pd.read_csv('icu/d_items.csv.gz')\n",
    "\n",
    "# 查找与血压相关的监测项\n",
    "blood_pressure_items = d_items[d_items['label'].str.contains('blood pressure', case=False)]\n",
    "print(blood_pressure_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id   hadm_id   stay_id  caregiver_id            charttime  \\\n",
      "40     10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
      "65     10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
      "96     10005817  20626031  32604416        6770.0  2132-12-16 00:00:00   \n",
      "107    10005817  20626031  32604416        6770.0  2132-12-16 01:00:00   \n",
      "113    10005817  20626031  32604416        6770.0  2132-12-16 01:00:00   \n",
      "\n",
      "               storetime  itemid value  valuenum valueuom  warning  \n",
      "40   2132-12-16 00:02:00  220051    37      37.0     mmHg      0.0  \n",
      "65   2132-12-16 00:02:00  220052    58      58.0     mmHg      0.0  \n",
      "96   2132-12-16 00:02:00  220050   117     117.0     mmHg      0.0  \n",
      "107  2132-12-16 01:04:00  220052    63      63.0     mmHg      0.0  \n",
      "113  2132-12-16 01:04:00  220051    40      40.0     mmHg      0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载 chartevents 表\n",
    "chartevents = pd.read_csv('icu/chartevents.csv.gz')\n",
    "\n",
    "# 筛选与血压相关的数据（使用 item_id）\n",
    "blood_pressure_ids = [220050, 220051, 220052, 220179, 220180, 220181]\n",
    "bp_data = chartevents[chartevents['itemid'].isin(blood_pressure_ids)]\n",
    "\n",
    "# 查看前几行数据\n",
    "print(bp_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id  seq_num icd_code  icd_version   stay_id  \\\n",
      "0    10025463  24470193        1      431            9  38275267   \n",
      "1    10025463  24470193        1      431            9  38275267   \n",
      "2    10025463  24470193        1      431            9  38275267   \n",
      "3    10025463  24470193        1      431            9  38275267   \n",
      "4    10025463  24470193        1      431            9  38275267   \n",
      "\n",
      "   caregiver_id            charttime            storetime  itemid value  \\\n",
      "0       34766.0  2137-10-09 03:00:00  2137-10-09 03:27:00  220052   102   \n",
      "1       34766.0  2137-10-09 03:00:00  2137-10-09 03:27:00  220051    80   \n",
      "2       34766.0  2137-10-09 03:00:00  2137-10-09 03:27:00  220050   134   \n",
      "3       34766.0  2137-10-09 04:00:00  2137-10-09 04:28:00  220050   144   \n",
      "4       34766.0  2137-10-09 04:00:00  2137-10-09 04:28:00  220051    82   \n",
      "\n",
      "   valuenum valueuom  warning  \n",
      "0     102.0     mmHg      0.0  \n",
      "1      80.0     mmHg      0.0  \n",
      "2     134.0     mmHg      0.0  \n",
      "3     144.0     mmHg      0.0  \n",
      "4      82.0     mmHg      0.0  \n"
     ]
    }
   ],
   "source": [
    "# 假设 stroke_data 已经从 diagnoses_icd.csv 中筛选出来\n",
    "merged_data = pd.merge(stroke_data, bp_data, on=['subject_id', 'hadm_id'], how='inner')\n",
    "\n",
    "# 查看合并后的数据\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "0    102\n",
      "1     80\n",
      "2    134\n",
      "3    144\n",
      "4     82\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 将 'value' 列转换为浮点数类型，无法转换的值将被设置为 NaN\n",
    "merged_data['value'] = pd.to_numeric(merged_data['value'], errors='coerce')\n",
    "\n",
    "# 查看转换后的数据类型和前几行\n",
    "print(merged_data['value'].dtype)\n",
    "print(merged_data['value'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id   hadm_id  seq_num icd_code  icd_version   stay_id  \\\n",
      "1     10025463  24470193        1      431            9  38275267   \n",
      "4     10025463  24470193        1      431            9  38275267   \n",
      "8     10025463  24470193        1      431            9  38275267   \n",
      "9     10025463  24470193        1      431            9  38275267   \n",
      "12    10025463  24470193        1      431            9  38275267   \n",
      "\n",
      "    caregiver_id            charttime            storetime  itemid  value  \\\n",
      "1        34766.0  2137-10-09 03:00:00  2137-10-09 03:27:00  220051     80   \n",
      "4        34766.0  2137-10-09 04:00:00  2137-10-09 04:28:00  220051     82   \n",
      "8        34766.0  2137-10-09 06:00:00  2137-10-09 06:03:00  220051     70   \n",
      "9        51676.0  2137-10-09 07:00:00  2137-10-09 07:13:00  220051     71   \n",
      "12       51676.0  2137-10-09 08:00:00  2137-10-09 08:01:00  220051     70   \n",
      "\n",
      "    valuenum valueuom  warning  \n",
      "1       80.0     mmHg      0.0  \n",
      "4       82.0     mmHg      0.0  \n",
      "8       70.0     mmHg      0.0  \n",
      "9       71.0     mmHg      0.0  \n",
      "12      70.0     mmHg      0.0  \n"
     ]
    }
   ],
   "source": [
    "# 填充缺失的血压数据（以均值填充）\n",
    "merged_data['value'].fillna(merged_data['value'].mean(), inplace=True)\n",
    "\n",
    "# 筛选血压低于90的患者群体（假设‘value’表示收缩压）\n",
    "high_risk_group = merged_data[merged_data['value'] < 90]\n",
    "\n",
    "# 查看高危患者数据\n",
    "print(high_risk_group.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version',\n",
      "       'stay_id', 'caregiver_id', 'charttime', 'storetime', 'itemid', 'value',\n",
      "       'valuenum', 'valueuom', 'warning'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(high_risk_group.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version',\n",
      "       'stay_id', 'caregiver_id', 'charttime', 'storetime', 'itemid', 'value',\n",
      "       'valuenum', 'valueuom', 'warning', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 加载 admissions 数据表\n",
    "admissions = pd.read_csv('hosp/admissions.csv.gz')\n",
    "\n",
    "# 合并 admissions 表中的存活/死亡状态（hospital_expire_flag）\n",
    "merged_data = pd.merge(high_risk_group, admissions[['subject_id', 'hadm_id', 'hospital_expire_flag']], \n",
    "                       on=['subject_id', 'hadm_id'], how='inner')\n",
    "\n",
    "# 将 hospital_expire_flag 作为目标列\n",
    "merged_data = merged_data.rename(columns={'hospital_expire_flag': 'target'})\n",
    "\n",
    "# 确认合并后的数据是否有 'target' 列\n",
    "print(merged_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 对血压值进行标准化\n",
    "scaler = StandardScaler()\n",
    "high_risk_group['value'] = scaler.fit_transform(high_risk_group[['value']])\n",
    "\n",
    "# 划分特征和目标列\n",
    "X = merged_data.drop('target', axis=1)\n",
    "y = merged_data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2143-03-22 13:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 初始化并训练随机森林模型\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 进行预测\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2143-03-22 13:00:00'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 初始化并训练随机森林模型\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 打印混淆矩阵和分类报告\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
